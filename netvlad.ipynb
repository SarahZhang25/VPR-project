{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1OkRSSh9wbPM2BWAWIbuIm2DQYKe_VbXs","authorship_tag":"ABX9TyMfi6NjX0SuCbPTBargdVCQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"AroJ2h4G9PMg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701050482169,"user_tz":300,"elapsed":11728,"user":{"displayName":"Sarah Zhang","userId":"14865879240066643945"}},"outputId":"9ce122d1-0c18-4cb8-b102-fe59f6ca048b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/VNAV\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/VNAV/\n","# df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_example.csv\")\n"]},{"cell_type":"code","source":["# using https://github.com/lyakaap/NetVLAD-pytorch implementation\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","from netvlad import NetVLAD\n","from netvlad import EmbedNet\n","from hard_triplet_loss import HardTripletLoss\n","from torchvision.models import resnet18\n","\n","\n","# Discard layers at the end of base network\n","encoder = resnet18(pretrained=True)\n","base_model = nn.Sequential(\n","    encoder.conv1,\n","    encoder.bn1,\n","    encoder.relu,\n","    encoder.maxpool,\n","    encoder.layer1,\n","    encoder.layer2,\n","    encoder.layer3,\n","    encoder.layer4,\n",")\n","dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n","\n","# Define model for embedding\n","net_vlad = NetVLAD(num_clusters=32, dim=dim, alpha=1.0)\n","model = EmbedNet(base_model, net_vlad).cuda()\n","\n","# Define loss\n","criterion = HardTripletLoss(margin=0.1).cuda()\n"],"metadata":{"id":"jR_xyiyq-lVh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701050490816,"user_tz":300,"elapsed":3989,"user":{"displayName":"Sarah Zhang","userId":"14865879240066643945"}},"outputId":"c73b18b6-eb59-4096-aab5-e05ceea7922a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 148MB/s]\n"]}]},{"cell_type":"code","source":["\n","# This is just toy example. Typically, the number of samples in each classes are 4.\n","labels = torch.randint(0, 10, (40, )).long().cuda()\n","x = torch.rand(40, 3, 128, 128).cuda()\n","output = model(x)\n","# fw_output = model.forward(x)\n","\n","triplet_loss = criterion(output, labels)"],"metadata":{"id":"2hjTJS2-i0Rm","executionInfo":{"status":"ok","timestamp":1701051126208,"user_tz":300,"elapsed":267,"user":{"displayName":"Sarah Zhang","userId":"14865879240066643945"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0kPfVfmQZXw","executionInfo":{"status":"ok","timestamp":1701051130215,"user_tz":300,"elapsed":342,"user":{"displayName":"Sarah Zhang","userId":"14865879240066643945"}},"outputId":"69ad4372-3125-4c32-de52-6e948a5e7392"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.9619e-03, -3.8447e-04, -1.0705e-02,  ..., -1.1778e-02,\n","         -6.4315e-03, -6.2501e-03],\n","        [-2.3603e-03, -3.2227e-04, -1.0329e-02,  ..., -1.1645e-02,\n","         -5.1624e-03, -6.4710e-03],\n","        [-1.9879e-03, -9.0182e-06, -1.0040e-02,  ..., -1.1550e-02,\n","         -6.1690e-03, -6.1888e-03],\n","        ...,\n","        [-2.5051e-03, -5.5473e-04, -1.0517e-02,  ..., -1.1847e-02,\n","         -6.4067e-03, -6.3728e-03],\n","        [-2.0092e-03, -5.0645e-04, -1.0648e-02,  ..., -1.1548e-02,\n","         -6.0797e-03, -5.9868e-03],\n","        [-2.2812e-03, -2.5367e-04, -1.0423e-02,  ..., -1.1797e-02,\n","         -5.5962e-03, -6.1345e-03]], device='cuda:0', grad_fn=<DivBackward0>)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import numpy as np\n","print(np.all(torch.Tensor.numpy(fw_output.cpu() == output.cpu())))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ17-IAMQxV8","executionInfo":{"status":"ok","timestamp":1701050677124,"user_tz":300,"elapsed":5,"user":{"displayName":"Sarah Zhang","userId":"14865879240066643945"}},"outputId":"ba1a871a-4893-45bd-dca6-28f680f46ffe"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xn9hT-8ngvzc"},"execution_count":null,"outputs":[]}]}